{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8049456,"sourceType":"datasetVersion","datasetId":4746781}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"DL_Assignment_Part_B","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-07T22:40:36.124345Z","iopub.execute_input":"2024-04-07T22:40:36.125017Z","iopub.status.idle":"2024-04-07T22:40:36.453672Z","shell.execute_reply.started":"2024-04-07T22:40:36.124981Z","shell.execute_reply":"2024-04-07T22:40:36.451682Z"}}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.transforms import transforms\nfrom torch.utils.data import DataLoader, SubsetRandomSampler\nfrom sklearn.model_selection import train_test_split\nfrom torchvision import models\n\n# Check if CUDA is available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Define function for pretrain model\ndef pretrain_model(model_name, freeze_percent,freez_all_except_last_layer):\n    \n    \n    if model_name == 'resnet':\n        pretrained_model = models.resnet50(pretrained=True)\n    elif model_name == 'inception':\n        pretrained_model = models.inception_v3(pretrained=True)\n   \n    nodes_fc = pretrained_model.fc.in_features\n    pretrained_model.fc = nn.Linear(nodes_fc, 10)  # Change 10 to the number of classes\n\n    total_layers = sum(1 for _ in pretrained_model.children())\n    num_freeze = int(total_layers * freeze_percent)\n\n    if freez_all_except_last_layer == 'Yes':\n        for name, parameter in pretrained_model.named_parameters():\n            if not name.startswith('fc'):  # Exclude the last layer named 'fc'\n                parameter.requires_grad = False\n\n    if freez_all_except_last_layer == 'No':\n        count = 0\n        for name, name_chld in pretrained_model.named_children():\n            if count < num_freeze:\n                for parameter in name_chld.parameters():\n                    parameter.requires_grad = False  # Freeze the layer\n            else:\n                for parameter in name_chld.parameters():\n                    parameter.requires_grad = True  # Make the layer trainable\n            count += 1\n    return pretrained_model\n\n# Example usage\nfreeze_percent = 0.25  # Freeze 25% of layers\nfreez_all_except_last_layer = 'No'\nmodel_name = 'resnet'\nmodel = pretrain_model(model_name,freeze_percent,freez_all_except_last_layer)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T22:47:01.400080Z","iopub.execute_input":"2024-04-07T22:47:01.401133Z","iopub.status.idle":"2024-04-07T22:47:01.984943Z","shell.execute_reply.started":"2024-04-07T22:47:01.401097Z","shell.execute_reply":"2024-04-07T22:47:01.983924Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=2048, out_features=10, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndata_dir = '/kaggle/input/nature-12k-dataset/inaturalist_12K/train'\n\ndef data_load(data_dir,data_augumentation):\n    # Define data transformations\n    if data_augumentation == 'Yes':\n        transform = transforms.Compose([\n            transforms.RandomResizedCrop(224),  # Randomly crop and resize to 224x224\n            transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Randomly adjust brightness, contrast, saturation, and hue\n            transforms.RandomRotation(20),  # Randomly rotate the image by up to 20 degrees\n            transforms.ToTensor(),  # Convert images to PyTorch tensors\n            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize image tensors\n        ])\n\n    else:\n        transform = transforms.Compose([\n            transforms.Resize((224, 224)),  # Resize images to 224x224 (compatible with the CNN input size)\n            transforms.ToTensor(),  # Convert images to PyTorch tensors\n            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize image tensors\n        ])\n        \n    # Load the dataset using ImageFolder and apply transformations\n    training_data = ImageFolder(root=data_dir, transform=transform)\n    # Splitting train dataset into training and validation indices\n    train_index, val_index = train_test_split(list(range(len(training_data))), test_size=0.2, random_state=42)\n    # Create DataLoader instances for training and validation sets\n    random_train_sample = SubsetRandomSampler(train_index)\n    train_data = DataLoader(training_data, batch_size=32, sampler=random_train_sample)\n    random_val_sample = SubsetRandomSampler(val_index)\n    validation_data = DataLoader(training_data, batch_size=32, sampler=random_val_sample)\n    return train_data, validation_data","metadata":{"execution":{"iopub.status.busy":"2024-04-07T22:47:01.986855Z","iopub.execute_input":"2024-04-07T22:47:01.987514Z","iopub.status.idle":"2024-04-07T22:47:01.996477Z","shell.execute_reply.started":"2024-04-07T22:47:01.987486Z","shell.execute_reply":"2024-04-07T22:47:01.995626Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def train_on_train_data(model, train_data):\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    model.train()  # Set the model to training mode\n    training_loss = 0.0\n    correct_train_label = 0\n    total_train = 0\n    # Training loop\n    for inputs, labels in train_data:\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        training_loss += loss.item()\n\n        # Calculate training accuracy\n        _, pred = torch.max(outputs, 1)\n        correct_train_label += (pred == labels).sum().item()\n        total_train += labels.size(0)\n\n    # Calculate training loss and accuracy\n    avg_loss = training_loss / len(train_data)\n    train_accuracy = 100 * correct_train_label / total_train\n    return avg_loss, train_accuracy\n\n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-07T22:49:29.256632Z","iopub.execute_input":"2024-04-07T22:49:29.257016Z","iopub.status.idle":"2024-04-07T22:49:29.265020Z","shell.execute_reply.started":"2024-04-07T22:49:29.256982Z","shell.execute_reply":"2024-04-07T22:49:29.263977Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def test_on_valid_data(model, test_data):\n    model.eval()  # Set the model to evaluation mode\n    correct_val = 0\n    total_val = 0\n    with torch.no_grad():  # Turn off gradient calculation for validation\n        for inputs_val, labels_val in test_data:\n            inputs_val, labels_val = inputs_val.to(device), labels_val.to(device)\n            outputs_val = model(inputs_val)\n            _, predicted_val = torch.max(outputs_val, 1)\n            correct_val += (predicted_val == labels_val).sum().item()\n            total_val += labels_val.size(0)\n\n    # Calculate validation accuracy\n    valid_accuracy = 100 * correct_val / total_val\n    return valid_accuracy","metadata":{"execution":{"iopub.status.busy":"2024-04-07T22:47:02.012115Z","iopub.execute_input":"2024-04-07T22:47:02.012389Z","iopub.status.idle":"2024-04-07T22:47:02.023225Z","shell.execute_reply.started":"2024-04-07T22:47:02.012354Z","shell.execute_reply":"2024-04-07T22:47:02.022502Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Function to training model\ndef model_train(model, train_data, val_data,epochs):\n\n    criterion = nn.CrossEntropyLoss()\n    # optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    for epoch in range(epochs):\n        avg_loss, train_accuracy = train_on_train_data(model, train_data)\n        # Print training loss and accuracy\n        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {avg_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%')\n        wandb.log({'Train loss': avg_loss})\n        wandb.log({'Train accuracy': train_accuracy})\n\n\n        # Validation loop\n        val_accuracy = test_on_valid_data(model, val_data)\n        # Print validation accuracy\n        print(f'Epoch {epoch+1}/{epochs}, Validation Accuracy: {val_accuracy:.2f}%')\n        wandb.log({'val_accuracy': val_accuracy})\n        wandb.log({'epoch': epoch})\n\n    print('Training complete!')\n\n# Example usage\n# model_train(model, train_loader, val_loader)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T22:47:02.024221Z","iopub.execute_input":"2024-04-07T22:47:02.024492Z","iopub.status.idle":"2024-04-07T22:47:02.033972Z","shell.execute_reply.started":"2024-04-07T22:47:02.024469Z","shell.execute_reply":"2024-04-07T22:47:02.033162Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install wandb","metadata":{"execution":{"iopub.status.busy":"2024-04-07T22:47:02.034956Z","iopub.execute_input":"2024-04-07T22:47:02.035206Z","iopub.status.idle":"2024-04-07T22:47:13.972853Z","shell.execute_reply.started":"2024-04-07T22:47:02.035184Z","shell.execute_reply":"2024-04-07T22:47:13.971681Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.4)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.42.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\nimport wandb\nimport numpy as np\nfrom types import SimpleNamespace\nimport random\n\nwandb.login(key='bb3c7761be2856a8335d16d1483149380482ae9e')#bb3c7761be2856a8335d16d1483149380482ae9e\n\nsweep_config = {\n    'method': 'random',\n    'metric': {\n        'name': 'val_accuracy',\n        'goal': 'maximize'\n    },\n    'parameters': {\n        'epoch': {\n            'values': [6]\n        },\n        'freezing_percentage': {\n            'values': [0.8,0.9]\n        },\n        'model': {\n            'values': [ 'resnet']#,'inception']\n        }\n    }\n}\n\nsweep_id = wandb.sweep(sweep_config, project='DL_assignment_2_PartB')\n\n\ndef main():\n    '''\n    WandB calls main function each time with differnet combination.\n\n    We can retrive the same and use the same values for our hypermeters.\n\n    '''\n\n    with wandb.init() as run:\n        run_name=\"ep\"+str(wandb.config.epoch)+\"_fp-\"+str(wandb.config.freezing_percentage)+\"_model-\"+(wandb.config.model)\n        wandb.run.name=run_name\n# wandb.config.freezing_percentage   \"_fp-\"+str(wandb.config.freezing_percentage)+\n\n        model = pretrain_model(model_name = wandb.config.model,freeze_percent=wandb.config.freezing_percentage ,freez_all_except_last_layer='No')\n        model = model.to(device)\n\n        data_dir = '/kaggle/input/nature-12k-dataset/inaturalist_12K/train'\n        train, validation = data_load(data_dir,data_augumentation= 'No')\n\n        model_train(model,train,validation,epochs=wandb.config.epoch)\n\nwandb.agent(sweep_id, function= main,count= 1) # calls main function for count number of times.\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T22:49:49.415591Z","iopub.execute_input":"2024-04-07T22:49:49.415962Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"name":"stdout","text":"Create sweep with ID: zffq76ui\nSweep URL: https://wandb.ai/abanisingha1997/DL_assignment_2_PartB/sweeps/zffq76ui\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8bkdx1xy with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 6\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfreezing_percentage: 0.9\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: resnet\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240407_224952-8bkdx1xy</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/abanisingha1997/DL_assignment_2_PartB/runs/8bkdx1xy' target=\"_blank\">good-sweep-1</a></strong> to <a href='https://wandb.ai/abanisingha1997/DL_assignment_2_PartB' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/abanisingha1997/DL_assignment_2_PartB/sweeps/zffq76ui' target=\"_blank\">https://wandb.ai/abanisingha1997/DL_assignment_2_PartB/sweeps/zffq76ui</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/abanisingha1997/DL_assignment_2_PartB' target=\"_blank\">https://wandb.ai/abanisingha1997/DL_assignment_2_PartB</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/abanisingha1997/DL_assignment_2_PartB/sweeps/zffq76ui' target=\"_blank\">https://wandb.ai/abanisingha1997/DL_assignment_2_PartB/sweeps/zffq76ui</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/abanisingha1997/DL_assignment_2_PartB/runs/8bkdx1xy' target=\"_blank\">https://wandb.ai/abanisingha1997/DL_assignment_2_PartB/runs/8bkdx1xy</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/6, Train Loss: 1.1011, Train Accuracy: 65.27%\nEpoch 1/6, Validation Accuracy: 72.75%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}