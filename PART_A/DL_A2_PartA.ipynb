{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7999589,"sourceType":"datasetVersion","datasetId":4710595}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.transforms import transforms\nfrom torch.utils.data import DataLoader, SubsetRandomSampler\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n# Check if CUDA is available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Function to calculate the image width and height in each for different sizes of kernels and different out channels\ndef img_size(img_w, filter_size, padding, stride):\n    return (1 / 2) * (1 + (img_w - filter_size + (2 * padding)) / stride)\n\nclass ConvNet(nn.Module):\n    def __init__(self, in_channels=3, num_filters=[32, 64, 128, 256, 512], filter_size=[3, 3, 5, 5, 7],\n                 activation=nn.ReLU(), stride=1, padding=1, pool_size=(2, 2), fc_size=512, num_classes=10,\n                 dropout=0, batch_norm = 'Yes'):\n        super(ConvNet, self).__init__()\n        self.channels = in_channels\n        self.num_filters = num_filters\n        self.filter_size = filter_size\n        self.activation = activation\n        self.stride = stride\n        self.padding = padding\n        self.pool_size = pool_size\n        self.fc_size = fc_size\n        self.num_classes = num_classes\n        self.dropout = dropout\n        self.batch_norm = batch_norm\n\n        # Define convolutional layers\n        self.conv1 = nn.Conv2d(self.channels, self.num_filters[0], self.filter_size[0], stride=self.stride, padding=self.padding)\n        self.dropout1 = nn.Dropout2d(self.dropout)\n        self.conv2 = nn.Conv2d(self.num_filters[0], self.num_filters[1], self.filter_size[1], stride=self.stride,padding=self.padding)\n        self.dropout2 = nn.Dropout2d(self.dropout)\n        self.conv3 = nn.Conv2d(self.num_filters[1], self.num_filters[2], self.filter_size[2], stride=self.stride,padding=self.padding)\n        self.dropout3 = nn.Dropout2d(self.dropout)\n        self.conv4 = nn.Conv2d(self.num_filters[2], self.num_filters[3], self.filter_size[3], stride=self.stride,padding=self.padding)\n        self.dropout4 = nn.Dropout2d(self.dropout)\n        self.conv5 = nn.Conv2d(self.num_filters[3], self.num_filters[4], self.filter_size[4], stride=self.stride,padding=self.padding)\n        self.dropout5 = nn.Dropout2d(self.dropout)\n\n        # Define batch normalization layers\n        self.batchnorm1 = nn.BatchNorm2d(self.num_filters[0])\n        self.batchnorm2 = nn.BatchNorm2d(self.num_filters[1])\n        self.batchnorm3 = nn.BatchNorm2d(self.num_filters[2])\n        self.batchnorm4 = nn.BatchNorm2d(self.num_filters[3])\n        self.batchnorm5 = nn.BatchNorm2d(self.num_filters[4])\n\n        # Define activation function\n        self.activation = activation\n\n        # Define max pooling layers \n        self.pool = nn.MaxPool2d(self.pool_size, stride=2)  # for maxpool default stride is 2 and padding is 0\n        \n        \n        # Calculating image width and height after each layer\n        nxt_size1 = img_size(224, self.filter_size[0], self.padding, self.stride)\n        nxt_size2 = img_size(nxt_size1, self.filter_size[1], self.padding, self.stride)\n        nxt_size3 = img_size(nxt_size2, self.filter_size[2], self.padding, self.stride)\n        nxt_size4 = img_size(nxt_size3, self.filter_size[3], self.padding, self.stride)\n        nxt_size5 = img_size(nxt_size4, self.filter_size[4], self.padding, self.stride)\n        nxt_size5 = int(nxt_size5)\n\n        # Define dropout layer\n        self.dropout_layer = nn.Dropout1d(self.dropout)\n\n        # Define fully connected layer\n        self.fc = nn.Linear(self.num_filters[4] * (nxt_size5 ** 2), self.fc_size)\n        self.fc_bn = nn.BatchNorm1d(self.fc_size)  # Batch normalization for fully connected layer\n\n        # Output layer\n        self.output_layer = nn.Linear(self.fc_size, self.num_classes)\n    \n    # Forward propagation function\n    def forward(self, x):\n        # 1st conv layer\n        x = self.conv1(x)\n        if self.batch_norm == 'Yes':\n            x = self.batchnorm1(x)\n        else:\n            x = x\n        x = self.activation(x)\n        x = self.pool(x)\n        x = self.dropout1(x)\n        \n        \n        # 2nd conv layer\n        x = self.conv2(x)\n        if self.batch_norm == 'Yes':\n            x = self.batchnorm2(x)\n        else:\n            x = x\n        # x = self.batchnorm2(x)\n        x = self.activation(x)\n        x = self.pool(x)\n        x = self.dropout2(x)\n        \n        \n        # 3rd conv layer\n        x = self.conv3(x)\n        if self.batch_norm == 'Yes':\n            x = self.batchnorm3(x)\n        else:\n            x = x\n        x = self.activation(x)\n        x = self.pool(x)\n        x = self.dropout3(x)\n        \n        \n        # 4th conv layer\n        x = self.conv4(x)\n        if self.batch_norm == 'Yes':\n            x = self.batchnorm4(x)\n        else:\n            x = x\n        x = self.activation(x)\n        x = self.pool(x)\n        x = self.dropout4(x)\n        \n        # 5th conv layer\n        x = self.conv5(x)\n        if self.batch_norm == 'Yes':\n            x = self.batchnorm5(x)\n        else:\n            x = x\n        x = self.activation(x)\n        x = self.pool(x)\n        x = self.dropout5(x)\n\n        # Flatten the output for the fully connected layer\n        x = x.view(x.size(0), -1)\n\n        # Fully connected layers\n        x = self.fc(x)\n        # Batch normalization before activation\n        if self.batch_norm == 'Yes':\n            x = self.fc_bn(x)\n        else:\n            x = x\n        # x = self.fc_bn(x)  \n        x = self.activation(x)\n        # Apply dropout\n        x = self.dropout_layer(x)\n        # Output layer\n        x = self.output_layer(x)\n\n        return x\n\n# Making object of the ConvNet class\nmodel = ConvNet().to(device)\nprint(model)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T22:18:02.410565Z","iopub.execute_input":"2024-04-07T22:18:02.411645Z","iopub.status.idle":"2024-04-07T22:18:02.570107Z","shell.execute_reply.started":"2024-04-07T22:18:02.411601Z","shell.execute_reply":"2024-04-07T22:18:02.569127Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"ConvNet(\n  (activation): ReLU()\n  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (dropout1): Dropout2d(p=0, inplace=False)\n  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (dropout2): Dropout2d(p=0, inplace=False)\n  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n  (dropout3): Dropout2d(p=0, inplace=False)\n  (conv4): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n  (dropout4): Dropout2d(p=0, inplace=False)\n  (conv5): Conv2d(256, 512, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1))\n  (dropout5): Dropout2d(p=0, inplace=False)\n  (batchnorm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (batchnorm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (batchnorm3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (batchnorm4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (batchnorm5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (pool): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n  (dropout_layer): Dropout1d(p=0, inplace=False)\n  (fc): Linear(in_features=8192, out_features=512, bias=True)\n  (fc_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (output_layer): Linear(in_features=512, out_features=10, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Function to train the model on train data\ndef train_on_train_data(model, train_data):\n    criterion = nn.CrossEntropyLoss()\n    # optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()  # Set the model to training mode\n    training_loss = 0.0\n    correct_train_label = 0\n    total_train = 0\n    # Training loop\n    for inputs, labels in train_data:\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        training_loss += loss.item()\n\n        # Calculate training accuracy\n        _, pred = torch.max(outputs, 1)\n        correct_train_label += (pred == labels).sum().item()\n        total_train += labels.size(0)\n\n    # Calculate training loss and accuracy\n    avg_loss = training_loss / len(train_data)\n    train_accuracy = 100 * correct_train_label / total_train\n    return model, avg_loss, train_accuracy\n\n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-07T22:18:02.571888Z","iopub.execute_input":"2024-04-07T22:18:02.572542Z","iopub.status.idle":"2024-04-07T22:18:02.580209Z","shell.execute_reply.started":"2024-04-07T22:18:02.572508Z","shell.execute_reply":"2024-04-07T22:18:02.579227Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":" # Function to test the model \ndef test_on_valid_data(model, test_data):\n    model.eval()  # Set the model to evaluation mode\n    correct_val = 0\n    total_val = 0\n    with torch.no_grad():  # Turn off gradient calculation for validation\n        for inputs_val, labels_val in test_data:\n            inputs_val, labels_val = inputs_val.to(device), labels_val.to(device)\n            outputs_val = model(inputs_val)\n            _, predicted_val = torch.max(outputs_val, 1)\n            correct_val += (predicted_val == labels_val).sum().item()\n            total_val += labels_val.size(0)\n\n    # Calculate validation accuracy\n    valid_accuracy = 100 * correct_val / total_val\n    return valid_accuracy","metadata":{"execution":{"iopub.status.busy":"2024-04-07T22:18:02.581269Z","iopub.execute_input":"2024-04-07T22:18:02.581542Z","iopub.status.idle":"2024-04-07T22:18:02.596207Z","shell.execute_reply.started":"2024-04-07T22:18:02.581520Z","shell.execute_reply":"2024-04-07T22:18:02.595248Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Function to training model\ndef model_train_val(model, train_data, val_data,epochs):\n\n    criterion = nn.CrossEntropyLoss()\n    # optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    for epoch in range(epochs):\n        model, avg_loss, train_accuracy = train_on_train_data(model, train_data)\n        # Print training loss and accuracy\n        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {avg_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%')\n        wandb.log({'Train loss': avg_loss})\n        wandb.log({'Train accuracy': train_accuracy})\n\n        # Validation loop\n        val_accuracy = test_on_valid_data(model, val_data)\n        # Print validation accuracy\n        print(f'Epoch {epoch+1}/{epochs}, Validation Accuracy: {val_accuracy:.2f}%')\n        wandb.log({'val_accuracy': val_accuracy})\n        wandb.log({'epoch': epoch})\n    \n    print('Training complete!')\n\n# Example usage\n# model_train(model, train_loader, val_loader)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T22:18:02.597963Z","iopub.execute_input":"2024-04-07T22:18:02.598261Z","iopub.status.idle":"2024-04-07T22:18:02.608040Z","shell.execute_reply.started":"2024-04-07T22:18:02.598239Z","shell.execute_reply":"2024-04-07T22:18:02.607150Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Training data loader function\n\ntrain_data_dir = '/kaggle/input/nature-12k/inaturalist_12K/train'\n\ndef data_load(train_data_dir,data_augumentation):\n    # Define data transformations\n    if data_augumentation == 'Yes':\n        transform = transforms.Compose([\n            transforms.RandomResizedCrop(224),  # Randomly crop and resize to 224x224\n            transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Randomly adjust brightness, contrast, saturation, and hue\n            transforms.RandomRotation(20),  # Randomly rotate the image by up to 20 degrees\n            transforms.ToTensor(),  # Convert images to PyTorch tensors\n            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize image tensors\n        ])\n\n    else:\n        transform = transforms.Compose([\n            transforms.Resize((224, 224)),  # Resize images to 224x224 (compatible with the CNN input size)\n            transforms.ToTensor(),  # Convert images to PyTorch tensors\n            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize image tensors\n        ])\n    # Load the dataset using ImageFolder and apply transformations\n    training_data = ImageFolder(root=train_data_dir, transform=transform)\n    # Splitting train dataset into training and validation indices\n    train_index, val_index = train_test_split(list(range(len(training_data))), test_size=0.2, random_state=42)\n    # Create DataLoader instances for training and validation sets\n    random_train_sample = SubsetRandomSampler(train_index)\n    train_data = DataLoader(training_data, batch_size=32, sampler=random_train_sample)\n    random_val_sample = SubsetRandomSampler(val_index)\n    validation_data = DataLoader(training_data, batch_size=32, sampler=random_val_sample)\n    return train_data, validation_data","metadata":{"execution":{"iopub.status.busy":"2024-04-07T22:18:02.609215Z","iopub.execute_input":"2024-04-07T22:18:02.609921Z","iopub.status.idle":"2024-04-07T22:18:02.623867Z","shell.execute_reply.started":"2024-04-07T22:18:02.609889Z","shell.execute_reply":"2024-04-07T22:18:02.622815Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Test data loader function\ntest_data_dir = '/kaggle/input/nature-12k/inaturalist_12K/val'\n\ndef test_data_load(test_data_dir,data_augumentation):\n    data_dir = test_data_dir\n    # Define data transformations\n    if data_augumentation == 'Yes':\n        transform = transforms.Compose([\n            transforms.RandomResizedCrop(224),  # Randomly crop and resize to 224x224\n            transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Randomly adjust brightness, contrast, saturation, and hue\n            transforms.RandomRotation(20),  # Randomly rotate the image by up to 20 degrees\n            transforms.ToTensor(),  # Convert images to PyTorch tensors\n            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize image tensors\n        ])\n\n    else:\n        transform = transforms.Compose([\n            transforms.Resize((224, 224)),  # Resize images to 224x224 (compatible with the CNN input size)\n            transforms.ToTensor(),  # Convert images to PyTorch tensors\n            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize image tensors\n        ])\n    # Load the dataset using ImageFolder and apply transformations\n    test_data = ImageFolder(root=data_dir, transform=transform)\n    \n    testData = DataLoader(test_data, batch_size=32)\n    \n    return testData","metadata":{"execution":{"iopub.status.busy":"2024-04-07T22:18:02.625034Z","iopub.execute_input":"2024-04-07T22:18:02.625313Z","iopub.status.idle":"2024-04-07T22:18:02.638185Z","shell.execute_reply.started":"2024-04-07T22:18:02.625290Z","shell.execute_reply":"2024-04-07T22:18:02.637288Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"!pip install wandb","metadata":{"execution":{"iopub.status.busy":"2024-04-07T22:18:02.639295Z","iopub.execute_input":"2024-04-07T22:18:02.639588Z","iopub.status.idle":"2024-04-07T22:18:16.192236Z","shell.execute_reply.started":"2024-04-07T22:18:02.639566Z","shell.execute_reply":"2024-04-07T22:18:16.191076Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.4)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.42.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"import wandb\nimport numpy as np\nfrom types import SimpleNamespace\nimport random","metadata":{"execution":{"iopub.status.busy":"2024-04-07T22:18:16.195450Z","iopub.execute_input":"2024-04-07T22:18:16.195743Z","iopub.status.idle":"2024-04-07T22:18:16.868878Z","shell.execute_reply.started":"2024-04-07T22:18:16.195717Z","shell.execute_reply":"2024-04-07T22:18:16.868142Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"wandb.login(key='bb3c7761be2856a8335d16d1483149380482ae9e')#bb3c7761be2856a8335d16d1483149380482ae9e\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T22:18:16.869889Z","iopub.execute_input":"2024-04-07T22:18:16.870151Z","iopub.status.idle":"2024-04-07T22:18:18.698839Z","shell.execute_reply.started":"2024-04-07T22:18:16.870121Z","shell.execute_reply":"2024-04-07T22:18:18.697880Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"sweep_config = {\n    'method': 'bayes',\n    'metric': {\n      'name': 'val_accuracy',\n      'goal': 'maximize'\n    },\n    'parameters': {\n        'kernel_size':{\n            'values': [[3,3,3,3,3],[3,5,5,7,7],[3,5,3,5,7],[5,5,5,5,5]]#,[7,7,7,7,7]]\n        },\n        'dropout': {\n            'values': [0.3, 0.2]\n        },\n        'activation': {\n            'values': [ 'relu','mish','silu', 'gelu',]\n        },\n        'num_dense':{\n            'values': [128, 256]\n        },\n        'batch_norm':{\n            'values': ['Yes','No']\n        },\n        'filter_org':{\n            'values': [[128,128,64,64,32],[32,64,128,256,512],[32,32,32,32,32],[32,64,64,128,128]]\n        },\n        'data_aug': {\n            'values': ['No', 'Yes']\n        }\n    }\n}\n\nsweep_id = wandb.sweep(sweep=sweep_config, project='DL_assignment_2')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T22:18:18.700052Z","iopub.execute_input":"2024-04-07T22:18:18.700525Z","iopub.status.idle":"2024-04-07T22:18:32.545050Z","shell.execute_reply.started":"2024-04-07T22:18:18.700497Z","shell.execute_reply":"2024-04-07T22:18:32.544182Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Create sweep with ID: 59rfixpw\nSweep URL: https://wandb.ai/abanisingha1997/DL_assignment_2/sweeps/59rfixpw\n","output_type":"stream"}]},{"cell_type":"code","source":"def main():\n    '''\n    WandB calls main function each time with differnet combination.\n\n    We can retrive the same and use the same values for our hypermeters.\n\n    '''\n\n    with wandb.init() as run:\n        run_name=\"ks\"+str(wandb.config.kernel_size)+\"ac-\"+(wandb.config.activation)+\"_drop-\"+str(wandb.config.dropout)+\"_daug-\"+str(wandb.config.data_aug)+\"_fs-\"+str(wandb.config.filter_org)+\"_bn-\"+str(wandb.config.batch_norm)+\"_dence-\"+str(wandb.config.num_dense)\n        wandb.run.name=run_name\n\n        if  wandb.config.activation == 'relu':\n            activ=nn.ReLU()\n        elif wandb.config.activation == 'gelu':\n            activ=nn.GELU()\n        elif wandb.config.activation == 'silu':\n            activ=nn.SiLU()\n        elif wandb.config.activation == 'mish':\n            activ=nn.Mish()\n        \n        model = ConvNet(in_channels=3, num_filters=wandb.config.filter_org, filter_size=wandb.config.kernel_size, activation=activ, stride=1,\n                        padding=1, pool_size=(2,2), fc_size=wandb.config.num_dense, num_classes=10,dropout = wandb.config.dropout,batch_norm=wandb.config.batch_norm).to(device)\n\n#         data_dir = '/kaggle/input/nature-12k/inaturalist_12K/train'\n        train_data_dir = '/kaggle/input/nature-12k/inaturalist_12K/train'\n        train, validation = data_load(train_data_dir,data_augumentation= wandb.config.data_aug)\n        \n        model_train_val(model, train, validation, epochs = 7)\n        \n#         model_train(model,train,validation)\n        \nwandb.agent(sweep_id, function= main,count= 1) # calls main function for count number of times.\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T22:18:32.546505Z","iopub.execute_input":"2024-04-07T22:18:32.546775Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: brpp4l58 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: No\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_aug: Yes\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_org: [32, 64, 64, 128, 128]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: [5, 5, 5, 5, 5]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dense: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mabanisingha1997\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240407_221834-brpp4l58</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/abanisingha1997/DL_assignment_2/runs/brpp4l58' target=\"_blank\">cerulean-sweep-1</a></strong> to <a href='https://wandb.ai/abanisingha1997/DL_assignment_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/abanisingha1997/DL_assignment_2/sweeps/59rfixpw' target=\"_blank\">https://wandb.ai/abanisingha1997/DL_assignment_2/sweeps/59rfixpw</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/abanisingha1997/DL_assignment_2' target=\"_blank\">https://wandb.ai/abanisingha1997/DL_assignment_2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/abanisingha1997/DL_assignment_2/sweeps/59rfixpw' target=\"_blank\">https://wandb.ai/abanisingha1997/DL_assignment_2/sweeps/59rfixpw</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/abanisingha1997/DL_assignment_2/runs/brpp4l58' target=\"_blank\">https://wandb.ai/abanisingha1997/DL_assignment_2/runs/brpp4l58</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/7, Train Loss: 2.3086, Train Accuracy: 11.94%\nEpoch 1/7, Validation Accuracy: 13.70%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Best hyperparameter configuration for this model","metadata":{}},{"cell_type":"code","source":"num_filters=[128, 128, 64, 64, 32]\nfilter_size=[3, 3, 3, 3, 3]\nactivation=nn.Mish()\nfc_size=128\ndropout=0.3\nbatch_norm = 'Yes'\ndata_augumentation = 'No'\nepochs = 6","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_dir = '/kaggle/input/nature-12k/inaturalist_12K/val'\n\ntest_dataset = test_data_load(test_data_dir,data_augumentation)\n\ntrain_data_dir = '/kaggle/input/nature-12k/inaturalist_12K/train'\n# /kaggle/input/nature-12k/inaturalist_12K/train\ntrain_data , validation_data =  data_load(train_data_dir,data_augumentation)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport imageio\nimport os\nclasses = {0:'Amphibia',1:'Animalia',2:'Arachnida',3:'Aves',4:'Fungi',\n           5:'Insecta',6:'Mammalia',7:'Mollusca',8:'Plantae',9:'Reptilia'}\n# Function to training model\n\nmodel = ConvNet(in_channels=3, num_filters=[128, 128, 64, 64, 32], filter_size=[3, 3, 3, 3, 3],\n                 activation=nn.Mish(), stride=1, padding=1, pool_size=(2, 2), fc_size=128, num_classes=10,\n                 dropout=0.3, batch_norm = 'Yes').to(device)\n\ndef model_train_test(model, train_data, test_data,epochs):\n\n    criterion = nn.CrossEntropyLoss()\n    # optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    for epoch in range(epochs):\n        model, avg_loss, train_accuracy = train_on_train_data(model, train_data)\n        # Print training loss and accuracy\n        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {avg_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%')\n        wandb.log({'Train loss': avg_loss})\n        wandb.log({'Train accuracy': train_accuracy})\n\n\n    # Validation loop\n    val_accuracy = test_on_valid_data(model, test_data)\n    # Print validation accuracy\n    print(f'Epoch {epoch+1}/{epochs}, Validation Accuracy: {val_accuracy:.2f}%')\n    wandb.log({'test_accuracy': val_accuracy})\n    wandb.log({'epoch': epoch})\n    \n    # Plot images along with their labels and predicted labels\n    \n    print('Training complete!')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sweep_config = {\n    'method': 'bayes',\n    'metric': {\n      'name': 'val_accuracy',\n      'goal': 'maximize'\n    },\n    'parameters': {\n        'kernel_size':{\n            'values': [[3,3,3,3,3]]\n        },\n        'dropout': {\n            'values': [0.3]\n        },\n        'activation': {\n            'values': [ 'mish']\n        },\n        'num_dense':{\n            'values': [128]\n        },\n        'batch_norm':{\n            'values': ['Yes']\n        },\n        'filter_org':{\n            'values': [[128,128,64,64,32]]\n        },\n        'data_aug': {\n            'values': ['No']\n        }\n    }\n}\n\nsweep_id = wandb.sweep(sweep=sweep_config, project='DL_assignment_2')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main():\n    '''\n    WandB calls main function each time with differnet combination.\n\n    We can retrive the same and use the same values for our hypermeters.\n\n    '''\n\n    with wandb.init() as run:\n        run_name=\"ks\"+str(wandb.config.kernel_size)+\"ac-\"+(wandb.config.activation)+\"_drop-\"+str(wandb.config.dropout)+\"_daug-\"+str(wandb.config.data_aug)+\"_fs-\"+str(wandb.config.filter_org)+\"_bn-\"+str(wandb.config.batch_norm)+\"_dence-\"+str(wandb.config.num_dense)\n        wandb.run.name=run_name\n\n        if  wandb.config.activation == 'relu':\n            activ=nn.ReLU()\n        elif wandb.config.activation == 'gelu':\n            activ=nn.GELU()\n        elif wandb.config.activation == 'silu':\n            activ=nn.SiLU()\n        elif wandb.config.activation == 'mish':\n            activ=nn.Mish()\n        \n        model = ConvNet(in_channels=3, num_filters=wandb.config.filter_org, filter_size=wandb.config.kernel_size, activation=activ, stride=1,\n                        padding=1, pool_size=(2,2), fc_size=wandb.config.num_dense, num_classes=10,dropout = wandb.config.dropout,batch_norm=wandb.config.batch_norm).to(device)\n\n        \n        train_data_dir = '/kaggle/input/nature-12k/inaturalist_12K/train'\n        train_data, validation = data_load(train_data_dir,data_augumentation= wandb.config.data_aug)\n        \n        test_data_dir = '/kaggle/input/nature-12k/inaturalist_12K/val'\n        test_data = test_data_load(test_data_dir,data_augumentation = wandb.config.data_aug)\n        \n        model_train_test(model, train_data, test_data,epochs = 6)\n        \n\n        \nwandb.agent(sweep_id, function= main,count= 1) # calls main function for count number of times.\nwandb.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}